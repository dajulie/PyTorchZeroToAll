{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lec_9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNHsVjvSl4NMwcwf3otC/sP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ad6bdd87978e4d8bb5409e285589dd2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1795ee403f034d09b097957a240481c9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c95920683f6d4388ba88ba5eadbb8922",
              "IPY_MODEL_e0c9fd5ddf4148e6aa65c73086085bd9"
            ]
          }
        },
        "1795ee403f034d09b097957a240481c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c95920683f6d4388ba88ba5eadbb8922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_419b94089aa34aea8042ffa8e1f3e357",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 9912422,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 9912422,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e4209f4e89db48a6af1a63daa560dc8e"
          }
        },
        "e0c9fd5ddf4148e6aa65c73086085bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_10f42e0bb53c41059f033c8d78ebda8a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 9913344/? [00:00&lt;00:00, 25183840.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cbab045e9bcb4651aee75aa6767a0fd7"
          }
        },
        "419b94089aa34aea8042ffa8e1f3e357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e4209f4e89db48a6af1a63daa560dc8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10f42e0bb53c41059f033c8d78ebda8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cbab045e9bcb4651aee75aa6767a0fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "669f1fb2e1674994bbb60d95ca5fb2cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_49bafbf3317d4bd69a47c0c7648ad16d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a12d6bd36f5145f58315d1ec17adb042",
              "IPY_MODEL_fa7f3ea7b0b54b90985244429d761754"
            ]
          }
        },
        "49bafbf3317d4bd69a47c0c7648ad16d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a12d6bd36f5145f58315d1ec17adb042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_af3a3ae9c9024ea6a8edb67203c5ed7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_935f8ae3b26d42f9ae5cd8d0d8bddc75"
          }
        },
        "fa7f3ea7b0b54b90985244429d761754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ffe3acc85e3b431eb083edc7a233128f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 393924.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d09ac80428c34f9fb3962f83620239e4"
          }
        },
        "af3a3ae9c9024ea6a8edb67203c5ed7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "935f8ae3b26d42f9ae5cd8d0d8bddc75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ffe3acc85e3b431eb083edc7a233128f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d09ac80428c34f9fb3962f83620239e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71218b6560104724a1ff0545c4cda32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb6c9d291d3d495689753142eabc7cc5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee9b9dae59d14ca3ac579d77e43d5d7b",
              "IPY_MODEL_0b0073c0f9794933a032a9b2d576a323"
            ]
          }
        },
        "cb6c9d291d3d495689753142eabc7cc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee9b9dae59d14ca3ac579d77e43d5d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f49c98391484538a9b456b547b9bb2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1648877,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1648877,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb6a19b304ac45118137b04226c0db03"
          }
        },
        "0b0073c0f9794933a032a9b2d576a323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21fb8ddb72934e0ebba03f4b55ef72a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1649664/? [00:01&lt;00:00, 1570436.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dfc86c92a53340e49e2afacb6fca1f8d"
          }
        },
        "8f49c98391484538a9b456b547b9bb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb6a19b304ac45118137b04226c0db03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21fb8ddb72934e0ebba03f4b55ef72a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dfc86c92a53340e49e2afacb6fca1f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "915e9852499244078a6ec7cdc4819582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_09128d5107484ab2a2c5b972009c2428",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_954dc2ef828f4ff8b1989d939388991c",
              "IPY_MODEL_c2954ae20f4941b9b321c1843925cc3e"
            ]
          }
        },
        "09128d5107484ab2a2c5b972009c2428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "954dc2ef828f4ff8b1989d939388991c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_861c02814fcd43888d7dc21fd334b903",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4542,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4542,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af9ca8c44f4844a1a1192672753b6b1a"
          }
        },
        "c2954ae20f4941b9b321c1843925cc3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f2c8bdf6c8484b6393976fe49130945d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5120/? [00:00&lt;00:00, 15815.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc6eff44b8d0427b96ca36c56c2f00c1"
          }
        },
        "861c02814fcd43888d7dc21fd334b903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af9ca8c44f4844a1a1192672753b6b1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f2c8bdf6c8484b6393976fe49130945d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc6eff44b8d0427b96ca36c56c2f00c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dajulie/PyTorchZeroToAll/blob/main/lec_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE6d2tg-UNzK",
        "outputId": "ca2332a0-b556-44a6-82cc-7bf00dba2f59"
      },
      "source": [
        "from torch import nn, tensor, max\n",
        "import numpy as np\n",
        "\n",
        "Y = np.array([1, 0, 0])\n",
        "Y_pred1 = np.array([0.7, 0.2, 0.1])\n",
        "Y_pred2 = np.array([0.1, 0.3, 0.6])\n",
        "print(f'Loss1: {np.sum(-Y * np.log(Y_pred1)):.4f}')\n",
        "print(f'Loss2: {np.sum(-Y * np.log(Y_pred2)):.4f}')\n",
        "\n",
        "\n",
        "\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "Y = tensor([0], requires_grad=False)\n",
        "\n",
        "Y_pred1 = tensor([[2.0, 1.0, 0.1]])\n",
        "Y_pred2 = tensor([[0.5, 2.0, 0.3]])\n",
        "\n",
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)\n",
        "\n",
        "print(f'PyTorch Loss1: {l1.item():.4f} \\nPyTorch Loss2: {l2.item():.4f}')\n",
        "print(f'Y_pred1: {max(Y_pred1.data, 1)[1].item()}')\n",
        "print(f'Y_pred2: {max(Y_pred2.data, 1)[1].item()}')\n",
        "\n",
        "\n",
        "\n",
        "Y = tensor([2, 0, 1], requires_grad=False)\n",
        "\n",
        "Y_pred1 = tensor([[0.1, 0.2, 0.9],\n",
        "                  [1.1, 0.1, 0.2],\n",
        "                  [0.2, 2.1, 0.1]])\n",
        "\n",
        "Y_pred2 = tensor([[0.8, 0.2, 0.3],\n",
        "                  [0.2, 0.3, 0.5],\n",
        "                  [0.2, 0.2, 0.5]])\n",
        "\n",
        "l1 = loss(Y_pred1, Y)\n",
        "l2 = loss(Y_pred2, Y)\n",
        "print(f'Batch Loss1: {l1.item():.4f} \\nBatch Loss2: {l2.data:.4f}')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss1: 0.3567\n",
            "Loss2: 2.3026\n",
            "PyTorch Loss1: 0.4170 \n",
            "PyTorch Loss2: 1.8406\n",
            "Y_pred1: 0\n",
            "Y_pred2: 1\n",
            "Batch Loss1: 0.4966 \n",
            "Batch Loss2: 1.2389\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ad6bdd87978e4d8bb5409e285589dd2b",
            "1795ee403f034d09b097957a240481c9",
            "c95920683f6d4388ba88ba5eadbb8922",
            "e0c9fd5ddf4148e6aa65c73086085bd9",
            "419b94089aa34aea8042ffa8e1f3e357",
            "e4209f4e89db48a6af1a63daa560dc8e",
            "10f42e0bb53c41059f033c8d78ebda8a",
            "cbab045e9bcb4651aee75aa6767a0fd7",
            "669f1fb2e1674994bbb60d95ca5fb2cf",
            "49bafbf3317d4bd69a47c0c7648ad16d",
            "a12d6bd36f5145f58315d1ec17adb042",
            "fa7f3ea7b0b54b90985244429d761754",
            "af3a3ae9c9024ea6a8edb67203c5ed7a",
            "935f8ae3b26d42f9ae5cd8d0d8bddc75",
            "ffe3acc85e3b431eb083edc7a233128f",
            "d09ac80428c34f9fb3962f83620239e4",
            "71218b6560104724a1ff0545c4cda32d",
            "cb6c9d291d3d495689753142eabc7cc5",
            "ee9b9dae59d14ca3ac579d77e43d5d7b",
            "0b0073c0f9794933a032a9b2d576a323",
            "8f49c98391484538a9b456b547b9bb2d",
            "eb6a19b304ac45118137b04226c0db03",
            "21fb8ddb72934e0ebba03f4b55ef72a9",
            "dfc86c92a53340e49e2afacb6fca1f8d",
            "915e9852499244078a6ec7cdc4819582",
            "09128d5107484ab2a2c5b972009c2428",
            "954dc2ef828f4ff8b1989d939388991c",
            "c2954ae20f4941b9b321c1843925cc3e",
            "861c02814fcd43888d7dc21fd334b903",
            "af9ca8c44f4844a1a1192672753b6b1a",
            "f2c8bdf6c8484b6393976fe49130945d",
            "cc6eff44b8d0427b96ca36c56c2f00c1"
          ]
        },
        "id": "i2j22JIFYLBl",
        "outputId": "9c338f56-1881-4a9d-b12a-21198c75d82b"
      },
      "source": [
        "from __future__ import print_function\n",
        "from torch import nn, optim, cuda\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "batch_size = 64\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'Training MNIST Model on {device}\\n{\"=\" * 44}')\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                               train=True,\n",
        "                               transform=transforms.ToTensor(),\n",
        "                               download=True)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./mnist_data/',\n",
        "                              train=False,\n",
        "                              transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(784, 520)\n",
        "        self.l2 = nn.Linear(520, 320)\n",
        "        self.l3 = nn.Linear(320, 240)\n",
        "        self.l4 = nn.Linear(240, 120)\n",
        "        self.l5 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = F.relu(self.l1(x))\n",
        "        x = F.relu(self.l2(x))\n",
        "        x = F.relu(self.l3(x))\n",
        "        x = F.relu(self.l4(x))\n",
        "        return self.l5(x)\n",
        "\n",
        "\n",
        "model = Net()\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    for data, target in test_loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = model(data)\n",
        "        test_loss += criterion(output, target).item()\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'===========================\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    since = time.time()\n",
        "    for epoch in range(1, 10):\n",
        "        epoch_start = time.time()\n",
        "        train(epoch)\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "        test()\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n",
        "\n",
        "    m, s = divmod(time.time() - since, 60)\n",
        "    print(f'Total Time: {m:.0f}m {s:.0f}s\\nModel was trained on {device}!')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training MNIST Model on cpu\n",
            "============================================\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad6bdd87978e4d8bb5409e285589dd2b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./mnist_data/MNIST/raw/train-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "669f1fb2e1674994bbb60d95ca5fb2cf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./mnist_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71218b6560104724a1ff0545c4cda32d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./mnist_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 503: Service Unavailable\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "915e9852499244078a6ec7cdc4819582",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting ./mnist_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./mnist_data/MNIST/raw\n",
            "\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 | Batch Status: 0/60000 (0%) | Loss: 2.307884\n",
            "Train Epoch: 1 | Batch Status: 640/60000 (1%) | Loss: 2.306247\n",
            "Train Epoch: 1 | Batch Status: 1280/60000 (2%) | Loss: 2.310318\n",
            "Train Epoch: 1 | Batch Status: 1920/60000 (3%) | Loss: 2.304065\n",
            "Train Epoch: 1 | Batch Status: 2560/60000 (4%) | Loss: 2.303220\n",
            "Train Epoch: 1 | Batch Status: 3200/60000 (5%) | Loss: 2.295462\n",
            "Train Epoch: 1 | Batch Status: 3840/60000 (6%) | Loss: 2.304389\n",
            "Train Epoch: 1 | Batch Status: 4480/60000 (7%) | Loss: 2.306846\n",
            "Train Epoch: 1 | Batch Status: 5120/60000 (9%) | Loss: 2.305751\n",
            "Train Epoch: 1 | Batch Status: 5760/60000 (10%) | Loss: 2.299263\n",
            "Train Epoch: 1 | Batch Status: 6400/60000 (11%) | Loss: 2.302494\n",
            "Train Epoch: 1 | Batch Status: 7040/60000 (12%) | Loss: 2.297364\n",
            "Train Epoch: 1 | Batch Status: 7680/60000 (13%) | Loss: 2.303902\n",
            "Train Epoch: 1 | Batch Status: 8320/60000 (14%) | Loss: 2.298641\n",
            "Train Epoch: 1 | Batch Status: 8960/60000 (15%) | Loss: 2.298339\n",
            "Train Epoch: 1 | Batch Status: 9600/60000 (16%) | Loss: 2.295216\n",
            "Train Epoch: 1 | Batch Status: 10240/60000 (17%) | Loss: 2.303606\n",
            "Train Epoch: 1 | Batch Status: 10880/60000 (18%) | Loss: 2.294085\n",
            "Train Epoch: 1 | Batch Status: 11520/60000 (19%) | Loss: 2.295672\n",
            "Train Epoch: 1 | Batch Status: 12160/60000 (20%) | Loss: 2.293810\n",
            "Train Epoch: 1 | Batch Status: 12800/60000 (21%) | Loss: 2.298714\n",
            "Train Epoch: 1 | Batch Status: 13440/60000 (22%) | Loss: 2.301258\n",
            "Train Epoch: 1 | Batch Status: 14080/60000 (23%) | Loss: 2.305936\n",
            "Train Epoch: 1 | Batch Status: 14720/60000 (25%) | Loss: 2.304027\n",
            "Train Epoch: 1 | Batch Status: 15360/60000 (26%) | Loss: 2.296376\n",
            "Train Epoch: 1 | Batch Status: 16000/60000 (27%) | Loss: 2.293809\n",
            "Train Epoch: 1 | Batch Status: 16640/60000 (28%) | Loss: 2.298185\n",
            "Train Epoch: 1 | Batch Status: 17280/60000 (29%) | Loss: 2.302644\n",
            "Train Epoch: 1 | Batch Status: 17920/60000 (30%) | Loss: 2.296537\n",
            "Train Epoch: 1 | Batch Status: 18560/60000 (31%) | Loss: 2.300789\n",
            "Train Epoch: 1 | Batch Status: 19200/60000 (32%) | Loss: 2.292865\n",
            "Train Epoch: 1 | Batch Status: 19840/60000 (33%) | Loss: 2.292808\n",
            "Train Epoch: 1 | Batch Status: 20480/60000 (34%) | Loss: 2.283955\n",
            "Train Epoch: 1 | Batch Status: 21120/60000 (35%) | Loss: 2.296203\n",
            "Train Epoch: 1 | Batch Status: 21760/60000 (36%) | Loss: 2.296467\n",
            "Train Epoch: 1 | Batch Status: 22400/60000 (37%) | Loss: 2.297652\n",
            "Train Epoch: 1 | Batch Status: 23040/60000 (38%) | Loss: 2.300969\n",
            "Train Epoch: 1 | Batch Status: 23680/60000 (39%) | Loss: 2.294770\n",
            "Train Epoch: 1 | Batch Status: 24320/60000 (41%) | Loss: 2.289729\n",
            "Train Epoch: 1 | Batch Status: 24960/60000 (42%) | Loss: 2.289177\n",
            "Train Epoch: 1 | Batch Status: 25600/60000 (43%) | Loss: 2.287781\n",
            "Train Epoch: 1 | Batch Status: 26240/60000 (44%) | Loss: 2.288731\n",
            "Train Epoch: 1 | Batch Status: 26880/60000 (45%) | Loss: 2.290161\n",
            "Train Epoch: 1 | Batch Status: 27520/60000 (46%) | Loss: 2.287918\n",
            "Train Epoch: 1 | Batch Status: 28160/60000 (47%) | Loss: 2.289497\n",
            "Train Epoch: 1 | Batch Status: 28800/60000 (48%) | Loss: 2.292107\n",
            "Train Epoch: 1 | Batch Status: 29440/60000 (49%) | Loss: 2.284950\n",
            "Train Epoch: 1 | Batch Status: 30080/60000 (50%) | Loss: 2.284736\n",
            "Train Epoch: 1 | Batch Status: 30720/60000 (51%) | Loss: 2.292312\n",
            "Train Epoch: 1 | Batch Status: 31360/60000 (52%) | Loss: 2.280623\n",
            "Train Epoch: 1 | Batch Status: 32000/60000 (53%) | Loss: 2.293228\n",
            "Train Epoch: 1 | Batch Status: 32640/60000 (54%) | Loss: 2.295047\n",
            "Train Epoch: 1 | Batch Status: 33280/60000 (55%) | Loss: 2.289086\n",
            "Train Epoch: 1 | Batch Status: 33920/60000 (57%) | Loss: 2.273239\n",
            "Train Epoch: 1 | Batch Status: 34560/60000 (58%) | Loss: 2.285046\n",
            "Train Epoch: 1 | Batch Status: 35200/60000 (59%) | Loss: 2.272511\n",
            "Train Epoch: 1 | Batch Status: 35840/60000 (60%) | Loss: 2.281988\n",
            "Train Epoch: 1 | Batch Status: 36480/60000 (61%) | Loss: 2.280967\n",
            "Train Epoch: 1 | Batch Status: 37120/60000 (62%) | Loss: 2.279272\n",
            "Train Epoch: 1 | Batch Status: 37760/60000 (63%) | Loss: 2.277524\n",
            "Train Epoch: 1 | Batch Status: 38400/60000 (64%) | Loss: 2.271138\n",
            "Train Epoch: 1 | Batch Status: 39040/60000 (65%) | Loss: 2.278879\n",
            "Train Epoch: 1 | Batch Status: 39680/60000 (66%) | Loss: 2.269231\n",
            "Train Epoch: 1 | Batch Status: 40320/60000 (67%) | Loss: 2.265034\n",
            "Train Epoch: 1 | Batch Status: 40960/60000 (68%) | Loss: 2.284605\n",
            "Train Epoch: 1 | Batch Status: 41600/60000 (69%) | Loss: 2.263741\n",
            "Train Epoch: 1 | Batch Status: 42240/60000 (70%) | Loss: 2.267641\n",
            "Train Epoch: 1 | Batch Status: 42880/60000 (71%) | Loss: 2.261016\n",
            "Train Epoch: 1 | Batch Status: 43520/60000 (72%) | Loss: 2.267720\n",
            "Train Epoch: 1 | Batch Status: 44160/60000 (74%) | Loss: 2.258476\n",
            "Train Epoch: 1 | Batch Status: 44800/60000 (75%) | Loss: 2.255346\n",
            "Train Epoch: 1 | Batch Status: 45440/60000 (76%) | Loss: 2.264903\n",
            "Train Epoch: 1 | Batch Status: 46080/60000 (77%) | Loss: 2.236929\n",
            "Train Epoch: 1 | Batch Status: 46720/60000 (78%) | Loss: 2.264322\n",
            "Train Epoch: 1 | Batch Status: 47360/60000 (79%) | Loss: 2.262575\n",
            "Train Epoch: 1 | Batch Status: 48000/60000 (80%) | Loss: 2.224279\n",
            "Train Epoch: 1 | Batch Status: 48640/60000 (81%) | Loss: 2.247775\n",
            "Train Epoch: 1 | Batch Status: 49280/60000 (82%) | Loss: 2.236610\n",
            "Train Epoch: 1 | Batch Status: 49920/60000 (83%) | Loss: 2.216465\n",
            "Train Epoch: 1 | Batch Status: 50560/60000 (84%) | Loss: 2.227518\n",
            "Train Epoch: 1 | Batch Status: 51200/60000 (85%) | Loss: 2.217044\n",
            "Train Epoch: 1 | Batch Status: 51840/60000 (86%) | Loss: 2.203437\n",
            "Train Epoch: 1 | Batch Status: 52480/60000 (87%) | Loss: 2.202334\n",
            "Train Epoch: 1 | Batch Status: 53120/60000 (88%) | Loss: 2.157637\n",
            "Train Epoch: 1 | Batch Status: 53760/60000 (90%) | Loss: 2.178122\n",
            "Train Epoch: 1 | Batch Status: 54400/60000 (91%) | Loss: 2.168498\n",
            "Train Epoch: 1 | Batch Status: 55040/60000 (92%) | Loss: 2.160568\n",
            "Train Epoch: 1 | Batch Status: 55680/60000 (93%) | Loss: 2.121092\n",
            "Train Epoch: 1 | Batch Status: 56320/60000 (94%) | Loss: 2.109289\n",
            "Train Epoch: 1 | Batch Status: 56960/60000 (95%) | Loss: 2.100100\n",
            "Train Epoch: 1 | Batch Status: 57600/60000 (96%) | Loss: 2.077736\n",
            "Train Epoch: 1 | Batch Status: 58240/60000 (97%) | Loss: 1.994998\n",
            "Train Epoch: 1 | Batch Status: 58880/60000 (98%) | Loss: 2.011920\n",
            "Train Epoch: 1 | Batch Status: 59520/60000 (99%) | Loss: 2.026276\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0312, Accuracy: 4148/10000 (41%)\n",
            "Testing time: 0m 14s\n",
            "Train Epoch: 2 | Batch Status: 0/60000 (0%) | Loss: 2.054413\n",
            "Train Epoch: 2 | Batch Status: 640/60000 (1%) | Loss: 1.945300\n",
            "Train Epoch: 2 | Batch Status: 1280/60000 (2%) | Loss: 1.915202\n",
            "Train Epoch: 2 | Batch Status: 1920/60000 (3%) | Loss: 1.906471\n",
            "Train Epoch: 2 | Batch Status: 2560/60000 (4%) | Loss: 1.833657\n",
            "Train Epoch: 2 | Batch Status: 3200/60000 (5%) | Loss: 1.819955\n",
            "Train Epoch: 2 | Batch Status: 3840/60000 (6%) | Loss: 1.804367\n",
            "Train Epoch: 2 | Batch Status: 4480/60000 (7%) | Loss: 1.772646\n",
            "Train Epoch: 2 | Batch Status: 5120/60000 (9%) | Loss: 1.716864\n",
            "Train Epoch: 2 | Batch Status: 5760/60000 (10%) | Loss: 1.632702\n",
            "Train Epoch: 2 | Batch Status: 6400/60000 (11%) | Loss: 1.561109\n",
            "Train Epoch: 2 | Batch Status: 7040/60000 (12%) | Loss: 1.501200\n",
            "Train Epoch: 2 | Batch Status: 7680/60000 (13%) | Loss: 1.556515\n",
            "Train Epoch: 2 | Batch Status: 8320/60000 (14%) | Loss: 1.390567\n",
            "Train Epoch: 2 | Batch Status: 8960/60000 (15%) | Loss: 1.413912\n",
            "Train Epoch: 2 | Batch Status: 9600/60000 (16%) | Loss: 1.346929\n",
            "Train Epoch: 2 | Batch Status: 10240/60000 (17%) | Loss: 1.401416\n",
            "Train Epoch: 2 | Batch Status: 10880/60000 (18%) | Loss: 1.200135\n",
            "Train Epoch: 2 | Batch Status: 11520/60000 (19%) | Loss: 1.195248\n",
            "Train Epoch: 2 | Batch Status: 12160/60000 (20%) | Loss: 1.078392\n",
            "Train Epoch: 2 | Batch Status: 12800/60000 (21%) | Loss: 1.171274\n",
            "Train Epoch: 2 | Batch Status: 13440/60000 (22%) | Loss: 1.227435\n",
            "Train Epoch: 2 | Batch Status: 14080/60000 (23%) | Loss: 1.047045\n",
            "Train Epoch: 2 | Batch Status: 14720/60000 (25%) | Loss: 0.948660\n",
            "Train Epoch: 2 | Batch Status: 15360/60000 (26%) | Loss: 1.328278\n",
            "Train Epoch: 2 | Batch Status: 16000/60000 (27%) | Loss: 0.856523\n",
            "Train Epoch: 2 | Batch Status: 16640/60000 (28%) | Loss: 0.928677\n",
            "Train Epoch: 2 | Batch Status: 17280/60000 (29%) | Loss: 1.146929\n",
            "Train Epoch: 2 | Batch Status: 17920/60000 (30%) | Loss: 0.872396\n",
            "Train Epoch: 2 | Batch Status: 18560/60000 (31%) | Loss: 1.018741\n",
            "Train Epoch: 2 | Batch Status: 19200/60000 (32%) | Loss: 0.817846\n",
            "Train Epoch: 2 | Batch Status: 19840/60000 (33%) | Loss: 0.740531\n",
            "Train Epoch: 2 | Batch Status: 20480/60000 (34%) | Loss: 0.769863\n",
            "Train Epoch: 2 | Batch Status: 21120/60000 (35%) | Loss: 0.703753\n",
            "Train Epoch: 2 | Batch Status: 21760/60000 (36%) | Loss: 0.761258\n",
            "Train Epoch: 2 | Batch Status: 22400/60000 (37%) | Loss: 0.842590\n",
            "Train Epoch: 2 | Batch Status: 23040/60000 (38%) | Loss: 0.941809\n",
            "Train Epoch: 2 | Batch Status: 23680/60000 (39%) | Loss: 0.928165\n",
            "Train Epoch: 2 | Batch Status: 24320/60000 (41%) | Loss: 0.771529\n",
            "Train Epoch: 2 | Batch Status: 24960/60000 (42%) | Loss: 0.805096\n",
            "Train Epoch: 2 | Batch Status: 25600/60000 (43%) | Loss: 0.853817\n",
            "Train Epoch: 2 | Batch Status: 26240/60000 (44%) | Loss: 0.920823\n",
            "Train Epoch: 2 | Batch Status: 26880/60000 (45%) | Loss: 0.558687\n",
            "Train Epoch: 2 | Batch Status: 27520/60000 (46%) | Loss: 0.461889\n",
            "Train Epoch: 2 | Batch Status: 28160/60000 (47%) | Loss: 0.907030\n",
            "Train Epoch: 2 | Batch Status: 28800/60000 (48%) | Loss: 0.876435\n",
            "Train Epoch: 2 | Batch Status: 29440/60000 (49%) | Loss: 0.719903\n",
            "Train Epoch: 2 | Batch Status: 30080/60000 (50%) | Loss: 0.653507\n",
            "Train Epoch: 2 | Batch Status: 30720/60000 (51%) | Loss: 0.580702\n",
            "Train Epoch: 2 | Batch Status: 31360/60000 (52%) | Loss: 0.648213\n",
            "Train Epoch: 2 | Batch Status: 32000/60000 (53%) | Loss: 0.553967\n",
            "Train Epoch: 2 | Batch Status: 32640/60000 (54%) | Loss: 0.461780\n",
            "Train Epoch: 2 | Batch Status: 33280/60000 (55%) | Loss: 0.699782\n",
            "Train Epoch: 2 | Batch Status: 33920/60000 (57%) | Loss: 0.669198\n",
            "Train Epoch: 2 | Batch Status: 34560/60000 (58%) | Loss: 0.586365\n",
            "Train Epoch: 2 | Batch Status: 35200/60000 (59%) | Loss: 0.655790\n",
            "Train Epoch: 2 | Batch Status: 35840/60000 (60%) | Loss: 0.622715\n",
            "Train Epoch: 2 | Batch Status: 36480/60000 (61%) | Loss: 0.638163\n",
            "Train Epoch: 2 | Batch Status: 37120/60000 (62%) | Loss: 0.553379\n",
            "Train Epoch: 2 | Batch Status: 37760/60000 (63%) | Loss: 0.618174\n",
            "Train Epoch: 2 | Batch Status: 38400/60000 (64%) | Loss: 0.465339\n",
            "Train Epoch: 2 | Batch Status: 39040/60000 (65%) | Loss: 0.457329\n",
            "Train Epoch: 2 | Batch Status: 39680/60000 (66%) | Loss: 0.458264\n",
            "Train Epoch: 2 | Batch Status: 40320/60000 (67%) | Loss: 0.682203\n",
            "Train Epoch: 2 | Batch Status: 40960/60000 (68%) | Loss: 0.543491\n",
            "Train Epoch: 2 | Batch Status: 41600/60000 (69%) | Loss: 0.526608\n",
            "Train Epoch: 2 | Batch Status: 42240/60000 (70%) | Loss: 0.810207\n",
            "Train Epoch: 2 | Batch Status: 42880/60000 (71%) | Loss: 0.458013\n",
            "Train Epoch: 2 | Batch Status: 43520/60000 (72%) | Loss: 0.729890\n",
            "Train Epoch: 2 | Batch Status: 44160/60000 (74%) | Loss: 0.616400\n",
            "Train Epoch: 2 | Batch Status: 44800/60000 (75%) | Loss: 0.571262\n",
            "Train Epoch: 2 | Batch Status: 45440/60000 (76%) | Loss: 0.437182\n",
            "Train Epoch: 2 | Batch Status: 46080/60000 (77%) | Loss: 0.549666\n",
            "Train Epoch: 2 | Batch Status: 46720/60000 (78%) | Loss: 0.731660\n",
            "Train Epoch: 2 | Batch Status: 47360/60000 (79%) | Loss: 0.701342\n",
            "Train Epoch: 2 | Batch Status: 48000/60000 (80%) | Loss: 0.721650\n",
            "Train Epoch: 2 | Batch Status: 48640/60000 (81%) | Loss: 0.307435\n",
            "Train Epoch: 2 | Batch Status: 49280/60000 (82%) | Loss: 0.515313\n",
            "Train Epoch: 2 | Batch Status: 49920/60000 (83%) | Loss: 0.442183\n",
            "Train Epoch: 2 | Batch Status: 50560/60000 (84%) | Loss: 0.641165\n",
            "Train Epoch: 2 | Batch Status: 51200/60000 (85%) | Loss: 0.623829\n",
            "Train Epoch: 2 | Batch Status: 51840/60000 (86%) | Loss: 0.582393\n",
            "Train Epoch: 2 | Batch Status: 52480/60000 (87%) | Loss: 0.532357\n",
            "Train Epoch: 2 | Batch Status: 53120/60000 (88%) | Loss: 0.529125\n",
            "Train Epoch: 2 | Batch Status: 53760/60000 (90%) | Loss: 0.484681\n",
            "Train Epoch: 2 | Batch Status: 54400/60000 (91%) | Loss: 0.446081\n",
            "Train Epoch: 2 | Batch Status: 55040/60000 (92%) | Loss: 0.371540\n",
            "Train Epoch: 2 | Batch Status: 55680/60000 (93%) | Loss: 0.630579\n",
            "Train Epoch: 2 | Batch Status: 56320/60000 (94%) | Loss: 0.280529\n",
            "Train Epoch: 2 | Batch Status: 56960/60000 (95%) | Loss: 0.453780\n",
            "Train Epoch: 2 | Batch Status: 57600/60000 (96%) | Loss: 0.543506\n",
            "Train Epoch: 2 | Batch Status: 58240/60000 (97%) | Loss: 0.382681\n",
            "Train Epoch: 2 | Batch Status: 58880/60000 (98%) | Loss: 0.332150\n",
            "Train Epoch: 2 | Batch Status: 59520/60000 (99%) | Loss: 0.400320\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0073, Accuracy: 8628/10000 (86%)\n",
            "Testing time: 0m 14s\n",
            "Train Epoch: 3 | Batch Status: 0/60000 (0%) | Loss: 0.397770\n",
            "Train Epoch: 3 | Batch Status: 640/60000 (1%) | Loss: 0.351269\n",
            "Train Epoch: 3 | Batch Status: 1280/60000 (2%) | Loss: 0.581039\n",
            "Train Epoch: 3 | Batch Status: 1920/60000 (3%) | Loss: 0.435594\n",
            "Train Epoch: 3 | Batch Status: 2560/60000 (4%) | Loss: 0.397410\n",
            "Train Epoch: 3 | Batch Status: 3200/60000 (5%) | Loss: 0.509163\n",
            "Train Epoch: 3 | Batch Status: 3840/60000 (6%) | Loss: 0.475616\n",
            "Train Epoch: 3 | Batch Status: 4480/60000 (7%) | Loss: 0.510392\n",
            "Train Epoch: 3 | Batch Status: 5120/60000 (9%) | Loss: 0.552092\n",
            "Train Epoch: 3 | Batch Status: 5760/60000 (10%) | Loss: 0.429767\n",
            "Train Epoch: 3 | Batch Status: 6400/60000 (11%) | Loss: 0.866933\n",
            "Train Epoch: 3 | Batch Status: 7040/60000 (12%) | Loss: 0.694821\n",
            "Train Epoch: 3 | Batch Status: 7680/60000 (13%) | Loss: 0.492259\n",
            "Train Epoch: 3 | Batch Status: 8320/60000 (14%) | Loss: 0.493754\n",
            "Train Epoch: 3 | Batch Status: 8960/60000 (15%) | Loss: 0.497635\n",
            "Train Epoch: 3 | Batch Status: 9600/60000 (16%) | Loss: 0.220678\n",
            "Train Epoch: 3 | Batch Status: 10240/60000 (17%) | Loss: 0.565613\n",
            "Train Epoch: 3 | Batch Status: 10880/60000 (18%) | Loss: 0.380090\n",
            "Train Epoch: 3 | Batch Status: 11520/60000 (19%) | Loss: 0.292037\n",
            "Train Epoch: 3 | Batch Status: 12160/60000 (20%) | Loss: 0.305637\n",
            "Train Epoch: 3 | Batch Status: 12800/60000 (21%) | Loss: 0.246578\n",
            "Train Epoch: 3 | Batch Status: 13440/60000 (22%) | Loss: 0.329236\n",
            "Train Epoch: 3 | Batch Status: 14080/60000 (23%) | Loss: 0.542558\n",
            "Train Epoch: 3 | Batch Status: 14720/60000 (25%) | Loss: 0.360798\n",
            "Train Epoch: 3 | Batch Status: 15360/60000 (26%) | Loss: 0.381140\n",
            "Train Epoch: 3 | Batch Status: 16000/60000 (27%) | Loss: 0.368805\n",
            "Train Epoch: 3 | Batch Status: 16640/60000 (28%) | Loss: 0.454977\n",
            "Train Epoch: 3 | Batch Status: 17280/60000 (29%) | Loss: 0.592106\n",
            "Train Epoch: 3 | Batch Status: 17920/60000 (30%) | Loss: 0.320408\n",
            "Train Epoch: 3 | Batch Status: 18560/60000 (31%) | Loss: 0.196944\n",
            "Train Epoch: 3 | Batch Status: 19200/60000 (32%) | Loss: 0.382204\n",
            "Train Epoch: 3 | Batch Status: 19840/60000 (33%) | Loss: 0.396804\n",
            "Train Epoch: 3 | Batch Status: 20480/60000 (34%) | Loss: 0.403754\n",
            "Train Epoch: 3 | Batch Status: 21120/60000 (35%) | Loss: 0.546419\n",
            "Train Epoch: 3 | Batch Status: 21760/60000 (36%) | Loss: 0.386395\n",
            "Train Epoch: 3 | Batch Status: 22400/60000 (37%) | Loss: 0.334527\n",
            "Train Epoch: 3 | Batch Status: 23040/60000 (38%) | Loss: 0.476690\n",
            "Train Epoch: 3 | Batch Status: 23680/60000 (39%) | Loss: 0.482864\n",
            "Train Epoch: 3 | Batch Status: 24320/60000 (41%) | Loss: 0.296748\n",
            "Train Epoch: 3 | Batch Status: 24960/60000 (42%) | Loss: 0.446159\n",
            "Train Epoch: 3 | Batch Status: 25600/60000 (43%) | Loss: 0.437475\n",
            "Train Epoch: 3 | Batch Status: 26240/60000 (44%) | Loss: 0.575273\n",
            "Train Epoch: 3 | Batch Status: 26880/60000 (45%) | Loss: 0.382135\n",
            "Train Epoch: 3 | Batch Status: 27520/60000 (46%) | Loss: 0.370165\n",
            "Train Epoch: 3 | Batch Status: 28160/60000 (47%) | Loss: 0.342153\n",
            "Train Epoch: 3 | Batch Status: 28800/60000 (48%) | Loss: 0.430817\n",
            "Train Epoch: 3 | Batch Status: 29440/60000 (49%) | Loss: 0.226970\n",
            "Train Epoch: 3 | Batch Status: 30080/60000 (50%) | Loss: 0.328262\n",
            "Train Epoch: 3 | Batch Status: 30720/60000 (51%) | Loss: 0.357809\n",
            "Train Epoch: 3 | Batch Status: 31360/60000 (52%) | Loss: 0.282939\n",
            "Train Epoch: 3 | Batch Status: 32000/60000 (53%) | Loss: 0.380728\n",
            "Train Epoch: 3 | Batch Status: 32640/60000 (54%) | Loss: 0.322256\n",
            "Train Epoch: 3 | Batch Status: 33280/60000 (55%) | Loss: 0.321944\n",
            "Train Epoch: 3 | Batch Status: 33920/60000 (57%) | Loss: 0.401466\n",
            "Train Epoch: 3 | Batch Status: 34560/60000 (58%) | Loss: 0.279014\n",
            "Train Epoch: 3 | Batch Status: 35200/60000 (59%) | Loss: 0.236972\n",
            "Train Epoch: 3 | Batch Status: 35840/60000 (60%) | Loss: 0.417857\n",
            "Train Epoch: 3 | Batch Status: 36480/60000 (61%) | Loss: 0.310956\n",
            "Train Epoch: 3 | Batch Status: 37120/60000 (62%) | Loss: 0.203002\n",
            "Train Epoch: 3 | Batch Status: 37760/60000 (63%) | Loss: 0.293856\n",
            "Train Epoch: 3 | Batch Status: 38400/60000 (64%) | Loss: 0.203660\n",
            "Train Epoch: 3 | Batch Status: 39040/60000 (65%) | Loss: 0.452020\n",
            "Train Epoch: 3 | Batch Status: 39680/60000 (66%) | Loss: 0.265536\n",
            "Train Epoch: 3 | Batch Status: 40320/60000 (67%) | Loss: 0.521547\n",
            "Train Epoch: 3 | Batch Status: 40960/60000 (68%) | Loss: 0.321183\n",
            "Train Epoch: 3 | Batch Status: 41600/60000 (69%) | Loss: 0.441828\n",
            "Train Epoch: 3 | Batch Status: 42240/60000 (70%) | Loss: 0.439287\n",
            "Train Epoch: 3 | Batch Status: 42880/60000 (71%) | Loss: 0.526720\n",
            "Train Epoch: 3 | Batch Status: 43520/60000 (72%) | Loss: 0.315758\n",
            "Train Epoch: 3 | Batch Status: 44160/60000 (74%) | Loss: 0.282976\n",
            "Train Epoch: 3 | Batch Status: 44800/60000 (75%) | Loss: 0.425584\n",
            "Train Epoch: 3 | Batch Status: 45440/60000 (76%) | Loss: 0.342216\n",
            "Train Epoch: 3 | Batch Status: 46080/60000 (77%) | Loss: 0.218885\n",
            "Train Epoch: 3 | Batch Status: 46720/60000 (78%) | Loss: 0.384080\n",
            "Train Epoch: 3 | Batch Status: 47360/60000 (79%) | Loss: 0.196748\n",
            "Train Epoch: 3 | Batch Status: 48000/60000 (80%) | Loss: 0.344278\n",
            "Train Epoch: 3 | Batch Status: 48640/60000 (81%) | Loss: 0.342888\n",
            "Train Epoch: 3 | Batch Status: 49280/60000 (82%) | Loss: 0.326159\n",
            "Train Epoch: 3 | Batch Status: 49920/60000 (83%) | Loss: 0.257329\n",
            "Train Epoch: 3 | Batch Status: 50560/60000 (84%) | Loss: 0.173734\n",
            "Train Epoch: 3 | Batch Status: 51200/60000 (85%) | Loss: 0.362218\n",
            "Train Epoch: 3 | Batch Status: 51840/60000 (86%) | Loss: 0.753607\n",
            "Train Epoch: 3 | Batch Status: 52480/60000 (87%) | Loss: 0.358922\n",
            "Train Epoch: 3 | Batch Status: 53120/60000 (88%) | Loss: 0.205863\n",
            "Train Epoch: 3 | Batch Status: 53760/60000 (90%) | Loss: 0.229007\n",
            "Train Epoch: 3 | Batch Status: 54400/60000 (91%) | Loss: 0.466918\n",
            "Train Epoch: 3 | Batch Status: 55040/60000 (92%) | Loss: 0.384128\n",
            "Train Epoch: 3 | Batch Status: 55680/60000 (93%) | Loss: 0.274550\n",
            "Train Epoch: 3 | Batch Status: 56320/60000 (94%) | Loss: 0.368313\n",
            "Train Epoch: 3 | Batch Status: 56960/60000 (95%) | Loss: 0.166665\n",
            "Train Epoch: 3 | Batch Status: 57600/60000 (96%) | Loss: 0.128410\n",
            "Train Epoch: 3 | Batch Status: 58240/60000 (97%) | Loss: 0.323462\n",
            "Train Epoch: 3 | Batch Status: 58880/60000 (98%) | Loss: 0.293970\n",
            "Train Epoch: 3 | Batch Status: 59520/60000 (99%) | Loss: 0.132191\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0048, Accuracy: 9085/10000 (91%)\n",
            "Testing time: 0m 14s\n",
            "Train Epoch: 4 | Batch Status: 0/60000 (0%) | Loss: 0.353548\n",
            "Train Epoch: 4 | Batch Status: 640/60000 (1%) | Loss: 0.376163\n",
            "Train Epoch: 4 | Batch Status: 1280/60000 (2%) | Loss: 0.407470\n",
            "Train Epoch: 4 | Batch Status: 1920/60000 (3%) | Loss: 0.223454\n",
            "Train Epoch: 4 | Batch Status: 2560/60000 (4%) | Loss: 0.211271\n",
            "Train Epoch: 4 | Batch Status: 3200/60000 (5%) | Loss: 0.397030\n",
            "Train Epoch: 4 | Batch Status: 3840/60000 (6%) | Loss: 0.208602\n",
            "Train Epoch: 4 | Batch Status: 4480/60000 (7%) | Loss: 0.453454\n",
            "Train Epoch: 4 | Batch Status: 5120/60000 (9%) | Loss: 0.137430\n",
            "Train Epoch: 4 | Batch Status: 5760/60000 (10%) | Loss: 0.328116\n",
            "Train Epoch: 4 | Batch Status: 6400/60000 (11%) | Loss: 0.396040\n",
            "Train Epoch: 4 | Batch Status: 7040/60000 (12%) | Loss: 0.379282\n",
            "Train Epoch: 4 | Batch Status: 7680/60000 (13%) | Loss: 0.351116\n",
            "Train Epoch: 4 | Batch Status: 8320/60000 (14%) | Loss: 0.283842\n",
            "Train Epoch: 4 | Batch Status: 8960/60000 (15%) | Loss: 0.348003\n",
            "Train Epoch: 4 | Batch Status: 9600/60000 (16%) | Loss: 0.322436\n",
            "Train Epoch: 4 | Batch Status: 10240/60000 (17%) | Loss: 0.141262\n",
            "Train Epoch: 4 | Batch Status: 10880/60000 (18%) | Loss: 0.357309\n",
            "Train Epoch: 4 | Batch Status: 11520/60000 (19%) | Loss: 0.465782\n",
            "Train Epoch: 4 | Batch Status: 12160/60000 (20%) | Loss: 0.467064\n",
            "Train Epoch: 4 | Batch Status: 12800/60000 (21%) | Loss: 0.155396\n",
            "Train Epoch: 4 | Batch Status: 13440/60000 (22%) | Loss: 0.296626\n",
            "Train Epoch: 4 | Batch Status: 14080/60000 (23%) | Loss: 0.224997\n",
            "Train Epoch: 4 | Batch Status: 14720/60000 (25%) | Loss: 0.225440\n",
            "Train Epoch: 4 | Batch Status: 15360/60000 (26%) | Loss: 0.551268\n",
            "Train Epoch: 4 | Batch Status: 16000/60000 (27%) | Loss: 0.453766\n",
            "Train Epoch: 4 | Batch Status: 16640/60000 (28%) | Loss: 0.271684\n",
            "Train Epoch: 4 | Batch Status: 17280/60000 (29%) | Loss: 0.280965\n",
            "Train Epoch: 4 | Batch Status: 17920/60000 (30%) | Loss: 0.546226\n",
            "Train Epoch: 4 | Batch Status: 18560/60000 (31%) | Loss: 0.260604\n",
            "Train Epoch: 4 | Batch Status: 19200/60000 (32%) | Loss: 0.150146\n",
            "Train Epoch: 4 | Batch Status: 19840/60000 (33%) | Loss: 0.333184\n",
            "Train Epoch: 4 | Batch Status: 20480/60000 (34%) | Loss: 0.152341\n",
            "Train Epoch: 4 | Batch Status: 21120/60000 (35%) | Loss: 0.109886\n",
            "Train Epoch: 4 | Batch Status: 21760/60000 (36%) | Loss: 0.345989\n",
            "Train Epoch: 4 | Batch Status: 22400/60000 (37%) | Loss: 0.361985\n",
            "Train Epoch: 4 | Batch Status: 23040/60000 (38%) | Loss: 0.229873\n",
            "Train Epoch: 4 | Batch Status: 23680/60000 (39%) | Loss: 0.402612\n",
            "Train Epoch: 4 | Batch Status: 24320/60000 (41%) | Loss: 0.178046\n",
            "Train Epoch: 4 | Batch Status: 24960/60000 (42%) | Loss: 0.369953\n",
            "Train Epoch: 4 | Batch Status: 25600/60000 (43%) | Loss: 0.221797\n",
            "Train Epoch: 4 | Batch Status: 26240/60000 (44%) | Loss: 0.301832\n",
            "Train Epoch: 4 | Batch Status: 26880/60000 (45%) | Loss: 0.221619\n",
            "Train Epoch: 4 | Batch Status: 27520/60000 (46%) | Loss: 0.195350\n",
            "Train Epoch: 4 | Batch Status: 28160/60000 (47%) | Loss: 0.415372\n",
            "Train Epoch: 4 | Batch Status: 28800/60000 (48%) | Loss: 0.273175\n",
            "Train Epoch: 4 | Batch Status: 29440/60000 (49%) | Loss: 0.271103\n",
            "Train Epoch: 4 | Batch Status: 30080/60000 (50%) | Loss: 0.288179\n",
            "Train Epoch: 4 | Batch Status: 30720/60000 (51%) | Loss: 0.268984\n",
            "Train Epoch: 4 | Batch Status: 31360/60000 (52%) | Loss: 0.139731\n",
            "Train Epoch: 4 | Batch Status: 32000/60000 (53%) | Loss: 0.239080\n",
            "Train Epoch: 4 | Batch Status: 32640/60000 (54%) | Loss: 0.333639\n",
            "Train Epoch: 4 | Batch Status: 33280/60000 (55%) | Loss: 0.269161\n",
            "Train Epoch: 4 | Batch Status: 33920/60000 (57%) | Loss: 0.307421\n",
            "Train Epoch: 4 | Batch Status: 34560/60000 (58%) | Loss: 0.239237\n",
            "Train Epoch: 4 | Batch Status: 35200/60000 (59%) | Loss: 0.162823\n",
            "Train Epoch: 4 | Batch Status: 35840/60000 (60%) | Loss: 0.187606\n",
            "Train Epoch: 4 | Batch Status: 36480/60000 (61%) | Loss: 0.414001\n",
            "Train Epoch: 4 | Batch Status: 37120/60000 (62%) | Loss: 0.354868\n",
            "Train Epoch: 4 | Batch Status: 37760/60000 (63%) | Loss: 0.251554\n",
            "Train Epoch: 4 | Batch Status: 38400/60000 (64%) | Loss: 0.345313\n",
            "Train Epoch: 4 | Batch Status: 39040/60000 (65%) | Loss: 0.192171\n",
            "Train Epoch: 4 | Batch Status: 39680/60000 (66%) | Loss: 0.233709\n",
            "Train Epoch: 4 | Batch Status: 40320/60000 (67%) | Loss: 0.220907\n",
            "Train Epoch: 4 | Batch Status: 40960/60000 (68%) | Loss: 0.381285\n",
            "Train Epoch: 4 | Batch Status: 41600/60000 (69%) | Loss: 0.275660\n",
            "Train Epoch: 4 | Batch Status: 42240/60000 (70%) | Loss: 0.193330\n",
            "Train Epoch: 4 | Batch Status: 42880/60000 (71%) | Loss: 0.183726\n",
            "Train Epoch: 4 | Batch Status: 43520/60000 (72%) | Loss: 0.113800\n",
            "Train Epoch: 4 | Batch Status: 44160/60000 (74%) | Loss: 0.331178\n",
            "Train Epoch: 4 | Batch Status: 44800/60000 (75%) | Loss: 0.100809\n",
            "Train Epoch: 4 | Batch Status: 45440/60000 (76%) | Loss: 0.209075\n",
            "Train Epoch: 4 | Batch Status: 46080/60000 (77%) | Loss: 0.318865\n",
            "Train Epoch: 4 | Batch Status: 46720/60000 (78%) | Loss: 0.268818\n",
            "Train Epoch: 4 | Batch Status: 47360/60000 (79%) | Loss: 0.285577\n",
            "Train Epoch: 4 | Batch Status: 48000/60000 (80%) | Loss: 0.461804\n",
            "Train Epoch: 4 | Batch Status: 48640/60000 (81%) | Loss: 0.484996\n",
            "Train Epoch: 4 | Batch Status: 49280/60000 (82%) | Loss: 0.269749\n",
            "Train Epoch: 4 | Batch Status: 49920/60000 (83%) | Loss: 0.143424\n",
            "Train Epoch: 4 | Batch Status: 50560/60000 (84%) | Loss: 0.162983\n",
            "Train Epoch: 4 | Batch Status: 51200/60000 (85%) | Loss: 0.270550\n",
            "Train Epoch: 4 | Batch Status: 51840/60000 (86%) | Loss: 0.198023\n",
            "Train Epoch: 4 | Batch Status: 52480/60000 (87%) | Loss: 0.181326\n",
            "Train Epoch: 4 | Batch Status: 53120/60000 (88%) | Loss: 0.283194\n",
            "Train Epoch: 4 | Batch Status: 53760/60000 (90%) | Loss: 0.195000\n",
            "Train Epoch: 4 | Batch Status: 54400/60000 (91%) | Loss: 0.171089\n",
            "Train Epoch: 4 | Batch Status: 55040/60000 (92%) | Loss: 0.283574\n",
            "Train Epoch: 4 | Batch Status: 55680/60000 (93%) | Loss: 0.196168\n",
            "Train Epoch: 4 | Batch Status: 56320/60000 (94%) | Loss: 0.291050\n",
            "Train Epoch: 4 | Batch Status: 56960/60000 (95%) | Loss: 0.083778\n",
            "Train Epoch: 4 | Batch Status: 57600/60000 (96%) | Loss: 0.134692\n",
            "Train Epoch: 4 | Batch Status: 58240/60000 (97%) | Loss: 0.304041\n",
            "Train Epoch: 4 | Batch Status: 58880/60000 (98%) | Loss: 0.108477\n",
            "Train Epoch: 4 | Batch Status: 59520/60000 (99%) | Loss: 0.417295\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0038, Accuracy: 9277/10000 (93%)\n",
            "Testing time: 0m 14s\n",
            "Train Epoch: 5 | Batch Status: 0/60000 (0%) | Loss: 0.242732\n",
            "Train Epoch: 5 | Batch Status: 640/60000 (1%) | Loss: 0.296192\n",
            "Train Epoch: 5 | Batch Status: 1280/60000 (2%) | Loss: 0.198153\n",
            "Train Epoch: 5 | Batch Status: 1920/60000 (3%) | Loss: 0.103724\n",
            "Train Epoch: 5 | Batch Status: 2560/60000 (4%) | Loss: 0.321957\n",
            "Train Epoch: 5 | Batch Status: 3200/60000 (5%) | Loss: 0.163557\n",
            "Train Epoch: 5 | Batch Status: 3840/60000 (6%) | Loss: 0.400660\n",
            "Train Epoch: 5 | Batch Status: 4480/60000 (7%) | Loss: 0.108075\n",
            "Train Epoch: 5 | Batch Status: 5120/60000 (9%) | Loss: 0.090630\n",
            "Train Epoch: 5 | Batch Status: 5760/60000 (10%) | Loss: 0.398940\n",
            "Train Epoch: 5 | Batch Status: 6400/60000 (11%) | Loss: 0.163147\n",
            "Train Epoch: 5 | Batch Status: 7040/60000 (12%) | Loss: 0.209424\n",
            "Train Epoch: 5 | Batch Status: 7680/60000 (13%) | Loss: 0.281752\n",
            "Train Epoch: 5 | Batch Status: 8320/60000 (14%) | Loss: 0.230690\n",
            "Train Epoch: 5 | Batch Status: 8960/60000 (15%) | Loss: 0.224429\n",
            "Train Epoch: 5 | Batch Status: 9600/60000 (16%) | Loss: 0.274513\n",
            "Train Epoch: 5 | Batch Status: 10240/60000 (17%) | Loss: 0.212596\n",
            "Train Epoch: 5 | Batch Status: 10880/60000 (18%) | Loss: 0.242928\n",
            "Train Epoch: 5 | Batch Status: 11520/60000 (19%) | Loss: 0.125192\n",
            "Train Epoch: 5 | Batch Status: 12160/60000 (20%) | Loss: 0.155707\n",
            "Train Epoch: 5 | Batch Status: 12800/60000 (21%) | Loss: 0.247579\n",
            "Train Epoch: 5 | Batch Status: 13440/60000 (22%) | Loss: 0.076041\n",
            "Train Epoch: 5 | Batch Status: 14080/60000 (23%) | Loss: 0.164397\n",
            "Train Epoch: 5 | Batch Status: 14720/60000 (25%) | Loss: 0.335158\n",
            "Train Epoch: 5 | Batch Status: 15360/60000 (26%) | Loss: 0.167424\n",
            "Train Epoch: 5 | Batch Status: 16000/60000 (27%) | Loss: 0.140762\n",
            "Train Epoch: 5 | Batch Status: 16640/60000 (28%) | Loss: 0.157162\n",
            "Train Epoch: 5 | Batch Status: 17280/60000 (29%) | Loss: 0.190049\n",
            "Train Epoch: 5 | Batch Status: 17920/60000 (30%) | Loss: 0.263032\n",
            "Train Epoch: 5 | Batch Status: 18560/60000 (31%) | Loss: 0.440956\n",
            "Train Epoch: 5 | Batch Status: 19200/60000 (32%) | Loss: 0.191794\n",
            "Train Epoch: 5 | Batch Status: 19840/60000 (33%) | Loss: 0.298227\n",
            "Train Epoch: 5 | Batch Status: 20480/60000 (34%) | Loss: 0.193167\n",
            "Train Epoch: 5 | Batch Status: 21120/60000 (35%) | Loss: 0.144165\n",
            "Train Epoch: 5 | Batch Status: 21760/60000 (36%) | Loss: 0.561748\n",
            "Train Epoch: 5 | Batch Status: 22400/60000 (37%) | Loss: 0.129667\n",
            "Train Epoch: 5 | Batch Status: 23040/60000 (38%) | Loss: 0.086056\n",
            "Train Epoch: 5 | Batch Status: 23680/60000 (39%) | Loss: 0.184291\n",
            "Train Epoch: 5 | Batch Status: 24320/60000 (41%) | Loss: 0.230140\n",
            "Train Epoch: 5 | Batch Status: 24960/60000 (42%) | Loss: 0.136252\n",
            "Train Epoch: 5 | Batch Status: 25600/60000 (43%) | Loss: 0.171992\n",
            "Train Epoch: 5 | Batch Status: 26240/60000 (44%) | Loss: 0.178140\n",
            "Train Epoch: 5 | Batch Status: 26880/60000 (45%) | Loss: 0.117256\n",
            "Train Epoch: 5 | Batch Status: 27520/60000 (46%) | Loss: 0.396554\n",
            "Train Epoch: 5 | Batch Status: 28160/60000 (47%) | Loss: 0.143058\n",
            "Train Epoch: 5 | Batch Status: 28800/60000 (48%) | Loss: 0.224594\n",
            "Train Epoch: 5 | Batch Status: 29440/60000 (49%) | Loss: 0.272287\n",
            "Train Epoch: 5 | Batch Status: 30080/60000 (50%) | Loss: 0.085704\n",
            "Train Epoch: 5 | Batch Status: 30720/60000 (51%) | Loss: 0.211851\n",
            "Train Epoch: 5 | Batch Status: 31360/60000 (52%) | Loss: 0.266651\n",
            "Train Epoch: 5 | Batch Status: 32000/60000 (53%) | Loss: 0.240987\n",
            "Train Epoch: 5 | Batch Status: 32640/60000 (54%) | Loss: 0.177898\n",
            "Train Epoch: 5 | Batch Status: 33280/60000 (55%) | Loss: 0.238614\n",
            "Train Epoch: 5 | Batch Status: 33920/60000 (57%) | Loss: 0.152215\n",
            "Train Epoch: 5 | Batch Status: 34560/60000 (58%) | Loss: 0.294004\n",
            "Train Epoch: 5 | Batch Status: 35200/60000 (59%) | Loss: 0.225154\n",
            "Train Epoch: 5 | Batch Status: 35840/60000 (60%) | Loss: 0.216005\n",
            "Train Epoch: 5 | Batch Status: 36480/60000 (61%) | Loss: 0.158168\n",
            "Train Epoch: 5 | Batch Status: 37120/60000 (62%) | Loss: 0.226635\n",
            "Train Epoch: 5 | Batch Status: 37760/60000 (63%) | Loss: 0.295677\n",
            "Train Epoch: 5 | Batch Status: 38400/60000 (64%) | Loss: 0.142521\n",
            "Train Epoch: 5 | Batch Status: 39040/60000 (65%) | Loss: 0.125311\n",
            "Train Epoch: 5 | Batch Status: 39680/60000 (66%) | Loss: 0.220698\n",
            "Train Epoch: 5 | Batch Status: 40320/60000 (67%) | Loss: 0.268165\n",
            "Train Epoch: 5 | Batch Status: 40960/60000 (68%) | Loss: 0.138245\n",
            "Train Epoch: 5 | Batch Status: 41600/60000 (69%) | Loss: 0.101936\n",
            "Train Epoch: 5 | Batch Status: 42240/60000 (70%) | Loss: 0.360503\n",
            "Train Epoch: 5 | Batch Status: 42880/60000 (71%) | Loss: 0.206110\n",
            "Train Epoch: 5 | Batch Status: 43520/60000 (72%) | Loss: 0.152907\n",
            "Train Epoch: 5 | Batch Status: 44160/60000 (74%) | Loss: 0.210101\n",
            "Train Epoch: 5 | Batch Status: 44800/60000 (75%) | Loss: 0.192915\n",
            "Train Epoch: 5 | Batch Status: 45440/60000 (76%) | Loss: 0.320990\n",
            "Train Epoch: 5 | Batch Status: 46080/60000 (77%) | Loss: 0.107546\n",
            "Train Epoch: 5 | Batch Status: 46720/60000 (78%) | Loss: 0.070339\n",
            "Train Epoch: 5 | Batch Status: 47360/60000 (79%) | Loss: 0.159138\n",
            "Train Epoch: 5 | Batch Status: 48000/60000 (80%) | Loss: 0.229709\n",
            "Train Epoch: 5 | Batch Status: 48640/60000 (81%) | Loss: 0.325374\n",
            "Train Epoch: 5 | Batch Status: 49280/60000 (82%) | Loss: 0.090178\n",
            "Train Epoch: 5 | Batch Status: 49920/60000 (83%) | Loss: 0.205577\n",
            "Train Epoch: 5 | Batch Status: 50560/60000 (84%) | Loss: 0.125829\n",
            "Train Epoch: 5 | Batch Status: 51200/60000 (85%) | Loss: 0.246587\n",
            "Train Epoch: 5 | Batch Status: 51840/60000 (86%) | Loss: 0.221350\n",
            "Train Epoch: 5 | Batch Status: 52480/60000 (87%) | Loss: 0.226976\n",
            "Train Epoch: 5 | Batch Status: 53120/60000 (88%) | Loss: 0.187228\n",
            "Train Epoch: 5 | Batch Status: 53760/60000 (90%) | Loss: 0.179583\n",
            "Train Epoch: 5 | Batch Status: 54400/60000 (91%) | Loss: 0.093228\n",
            "Train Epoch: 5 | Batch Status: 55040/60000 (92%) | Loss: 0.160530\n",
            "Train Epoch: 5 | Batch Status: 55680/60000 (93%) | Loss: 0.067520\n",
            "Train Epoch: 5 | Batch Status: 56320/60000 (94%) | Loss: 0.304302\n",
            "Train Epoch: 5 | Batch Status: 56960/60000 (95%) | Loss: 0.216152\n",
            "Train Epoch: 5 | Batch Status: 57600/60000 (96%) | Loss: 0.328876\n",
            "Train Epoch: 5 | Batch Status: 58240/60000 (97%) | Loss: 0.204299\n",
            "Train Epoch: 5 | Batch Status: 58880/60000 (98%) | Loss: 0.263896\n",
            "Train Epoch: 5 | Batch Status: 59520/60000 (99%) | Loss: 0.167297\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0027, Accuracy: 9478/10000 (95%)\n",
            "Testing time: 0m 14s\n",
            "Train Epoch: 6 | Batch Status: 0/60000 (0%) | Loss: 0.193820\n",
            "Train Epoch: 6 | Batch Status: 640/60000 (1%) | Loss: 0.082159\n",
            "Train Epoch: 6 | Batch Status: 1280/60000 (2%) | Loss: 0.149714\n",
            "Train Epoch: 6 | Batch Status: 1920/60000 (3%) | Loss: 0.069174\n",
            "Train Epoch: 6 | Batch Status: 2560/60000 (4%) | Loss: 0.119394\n",
            "Train Epoch: 6 | Batch Status: 3200/60000 (5%) | Loss: 0.130661\n",
            "Train Epoch: 6 | Batch Status: 3840/60000 (6%) | Loss: 0.239310\n",
            "Train Epoch: 6 | Batch Status: 4480/60000 (7%) | Loss: 0.101758\n",
            "Train Epoch: 6 | Batch Status: 5120/60000 (9%) | Loss: 0.160830\n",
            "Train Epoch: 6 | Batch Status: 5760/60000 (10%) | Loss: 0.073210\n",
            "Train Epoch: 6 | Batch Status: 6400/60000 (11%) | Loss: 0.217428\n",
            "Train Epoch: 6 | Batch Status: 7040/60000 (12%) | Loss: 0.088012\n",
            "Train Epoch: 6 | Batch Status: 7680/60000 (13%) | Loss: 0.169062\n",
            "Train Epoch: 6 | Batch Status: 8320/60000 (14%) | Loss: 0.083943\n",
            "Train Epoch: 6 | Batch Status: 8960/60000 (15%) | Loss: 0.173598\n",
            "Train Epoch: 6 | Batch Status: 9600/60000 (16%) | Loss: 0.281898\n",
            "Train Epoch: 6 | Batch Status: 10240/60000 (17%) | Loss: 0.327358\n",
            "Train Epoch: 6 | Batch Status: 10880/60000 (18%) | Loss: 0.136441\n",
            "Train Epoch: 6 | Batch Status: 11520/60000 (19%) | Loss: 0.111103\n",
            "Train Epoch: 6 | Batch Status: 12160/60000 (20%) | Loss: 0.270103\n",
            "Train Epoch: 6 | Batch Status: 12800/60000 (21%) | Loss: 0.170367\n",
            "Train Epoch: 6 | Batch Status: 13440/60000 (22%) | Loss: 0.337368\n",
            "Train Epoch: 6 | Batch Status: 14080/60000 (23%) | Loss: 0.154523\n",
            "Train Epoch: 6 | Batch Status: 14720/60000 (25%) | Loss: 0.343514\n",
            "Train Epoch: 6 | Batch Status: 15360/60000 (26%) | Loss: 0.049263\n",
            "Train Epoch: 6 | Batch Status: 16000/60000 (27%) | Loss: 0.126093\n",
            "Train Epoch: 6 | Batch Status: 16640/60000 (28%) | Loss: 0.252029\n",
            "Train Epoch: 6 | Batch Status: 17280/60000 (29%) | Loss: 0.347142\n",
            "Train Epoch: 6 | Batch Status: 17920/60000 (30%) | Loss: 0.087502\n",
            "Train Epoch: 6 | Batch Status: 18560/60000 (31%) | Loss: 0.101985\n",
            "Train Epoch: 6 | Batch Status: 19200/60000 (32%) | Loss: 0.196275\n",
            "Train Epoch: 6 | Batch Status: 19840/60000 (33%) | Loss: 0.187377\n",
            "Train Epoch: 6 | Batch Status: 20480/60000 (34%) | Loss: 0.044012\n",
            "Train Epoch: 6 | Batch Status: 21120/60000 (35%) | Loss: 0.199914\n",
            "Train Epoch: 6 | Batch Status: 21760/60000 (36%) | Loss: 0.222058\n",
            "Train Epoch: 6 | Batch Status: 22400/60000 (37%) | Loss: 0.116167\n",
            "Train Epoch: 6 | Batch Status: 23040/60000 (38%) | Loss: 0.126529\n",
            "Train Epoch: 6 | Batch Status: 23680/60000 (39%) | Loss: 0.134864\n",
            "Train Epoch: 6 | Batch Status: 24320/60000 (41%) | Loss: 0.217303\n",
            "Train Epoch: 6 | Batch Status: 24960/60000 (42%) | Loss: 0.133210\n",
            "Train Epoch: 6 | Batch Status: 25600/60000 (43%) | Loss: 0.070430\n",
            "Train Epoch: 6 | Batch Status: 26240/60000 (44%) | Loss: 0.144644\n",
            "Train Epoch: 6 | Batch Status: 26880/60000 (45%) | Loss: 0.174999\n",
            "Train Epoch: 6 | Batch Status: 27520/60000 (46%) | Loss: 0.117860\n",
            "Train Epoch: 6 | Batch Status: 28160/60000 (47%) | Loss: 0.173620\n",
            "Train Epoch: 6 | Batch Status: 28800/60000 (48%) | Loss: 0.045395\n",
            "Train Epoch: 6 | Batch Status: 29440/60000 (49%) | Loss: 0.273001\n",
            "Train Epoch: 6 | Batch Status: 30080/60000 (50%) | Loss: 0.111339\n",
            "Train Epoch: 6 | Batch Status: 30720/60000 (51%) | Loss: 0.064667\n",
            "Train Epoch: 6 | Batch Status: 31360/60000 (52%) | Loss: 0.180420\n",
            "Train Epoch: 6 | Batch Status: 32000/60000 (53%) | Loss: 0.161098\n",
            "Train Epoch: 6 | Batch Status: 32640/60000 (54%) | Loss: 0.222329\n",
            "Train Epoch: 6 | Batch Status: 33280/60000 (55%) | Loss: 0.248298\n",
            "Train Epoch: 6 | Batch Status: 33920/60000 (57%) | Loss: 0.157789\n",
            "Train Epoch: 6 | Batch Status: 34560/60000 (58%) | Loss: 0.136938\n",
            "Train Epoch: 6 | Batch Status: 35200/60000 (59%) | Loss: 0.223980\n",
            "Train Epoch: 6 | Batch Status: 35840/60000 (60%) | Loss: 0.213024\n",
            "Train Epoch: 6 | Batch Status: 36480/60000 (61%) | Loss: 0.064200\n",
            "Train Epoch: 6 | Batch Status: 37120/60000 (62%) | Loss: 0.099632\n",
            "Train Epoch: 6 | Batch Status: 37760/60000 (63%) | Loss: 0.156667\n",
            "Train Epoch: 6 | Batch Status: 38400/60000 (64%) | Loss: 0.184431\n",
            "Train Epoch: 6 | Batch Status: 39040/60000 (65%) | Loss: 0.128834\n",
            "Train Epoch: 6 | Batch Status: 39680/60000 (66%) | Loss: 0.119449\n",
            "Train Epoch: 6 | Batch Status: 40320/60000 (67%) | Loss: 0.108914\n",
            "Train Epoch: 6 | Batch Status: 40960/60000 (68%) | Loss: 0.128177\n",
            "Train Epoch: 6 | Batch Status: 41600/60000 (69%) | Loss: 0.088752\n",
            "Train Epoch: 6 | Batch Status: 42240/60000 (70%) | Loss: 0.261591\n",
            "Train Epoch: 6 | Batch Status: 42880/60000 (71%) | Loss: 0.183904\n",
            "Train Epoch: 6 | Batch Status: 43520/60000 (72%) | Loss: 0.155667\n",
            "Train Epoch: 6 | Batch Status: 44160/60000 (74%) | Loss: 0.154669\n",
            "Train Epoch: 6 | Batch Status: 44800/60000 (75%) | Loss: 0.187373\n",
            "Train Epoch: 6 | Batch Status: 45440/60000 (76%) | Loss: 0.095059\n",
            "Train Epoch: 6 | Batch Status: 46080/60000 (77%) | Loss: 0.275229\n",
            "Train Epoch: 6 | Batch Status: 46720/60000 (78%) | Loss: 0.209164\n",
            "Train Epoch: 6 | Batch Status: 47360/60000 (79%) | Loss: 0.156148\n",
            "Train Epoch: 6 | Batch Status: 48000/60000 (80%) | Loss: 0.280064\n",
            "Train Epoch: 6 | Batch Status: 48640/60000 (81%) | Loss: 0.131849\n",
            "Train Epoch: 6 | Batch Status: 49280/60000 (82%) | Loss: 0.126027\n",
            "Train Epoch: 6 | Batch Status: 49920/60000 (83%) | Loss: 0.125124\n",
            "Train Epoch: 6 | Batch Status: 50560/60000 (84%) | Loss: 0.172860\n",
            "Train Epoch: 6 | Batch Status: 51200/60000 (85%) | Loss: 0.218326\n",
            "Train Epoch: 6 | Batch Status: 51840/60000 (86%) | Loss: 0.138862\n",
            "Train Epoch: 6 | Batch Status: 52480/60000 (87%) | Loss: 0.228951\n",
            "Train Epoch: 6 | Batch Status: 53120/60000 (88%) | Loss: 0.131778\n",
            "Train Epoch: 6 | Batch Status: 53760/60000 (90%) | Loss: 0.130922\n",
            "Train Epoch: 6 | Batch Status: 54400/60000 (91%) | Loss: 0.096636\n",
            "Train Epoch: 6 | Batch Status: 55040/60000 (92%) | Loss: 0.111629\n",
            "Train Epoch: 6 | Batch Status: 55680/60000 (93%) | Loss: 0.217960\n",
            "Train Epoch: 6 | Batch Status: 56320/60000 (94%) | Loss: 0.103019\n",
            "Train Epoch: 6 | Batch Status: 56960/60000 (95%) | Loss: 0.111125\n",
            "Train Epoch: 6 | Batch Status: 57600/60000 (96%) | Loss: 0.047406\n",
            "Train Epoch: 6 | Batch Status: 58240/60000 (97%) | Loss: 0.403803\n",
            "Train Epoch: 6 | Batch Status: 58880/60000 (98%) | Loss: 0.107726\n",
            "Train Epoch: 6 | Batch Status: 59520/60000 (99%) | Loss: 0.043287\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0025, Accuracy: 9526/10000 (95%)\n",
            "Testing time: 0m 14s\n",
            "Train Epoch: 7 | Batch Status: 0/60000 (0%) | Loss: 0.114870\n",
            "Train Epoch: 7 | Batch Status: 640/60000 (1%) | Loss: 0.078940\n",
            "Train Epoch: 7 | Batch Status: 1280/60000 (2%) | Loss: 0.104627\n",
            "Train Epoch: 7 | Batch Status: 1920/60000 (3%) | Loss: 0.102036\n",
            "Train Epoch: 7 | Batch Status: 2560/60000 (4%) | Loss: 0.208910\n",
            "Train Epoch: 7 | Batch Status: 3200/60000 (5%) | Loss: 0.221871\n",
            "Train Epoch: 7 | Batch Status: 3840/60000 (6%) | Loss: 0.029921\n",
            "Train Epoch: 7 | Batch Status: 4480/60000 (7%) | Loss: 0.421595\n",
            "Train Epoch: 7 | Batch Status: 5120/60000 (9%) | Loss: 0.154168\n",
            "Train Epoch: 7 | Batch Status: 5760/60000 (10%) | Loss: 0.190167\n",
            "Train Epoch: 7 | Batch Status: 6400/60000 (11%) | Loss: 0.067870\n",
            "Train Epoch: 7 | Batch Status: 7040/60000 (12%) | Loss: 0.188018\n",
            "Train Epoch: 7 | Batch Status: 7680/60000 (13%) | Loss: 0.054987\n",
            "Train Epoch: 7 | Batch Status: 8320/60000 (14%) | Loss: 0.168518\n",
            "Train Epoch: 7 | Batch Status: 8960/60000 (15%) | Loss: 0.108069\n",
            "Train Epoch: 7 | Batch Status: 9600/60000 (16%) | Loss: 0.123384\n",
            "Train Epoch: 7 | Batch Status: 10240/60000 (17%) | Loss: 0.431934\n",
            "Train Epoch: 7 | Batch Status: 10880/60000 (18%) | Loss: 0.112932\n",
            "Train Epoch: 7 | Batch Status: 11520/60000 (19%) | Loss: 0.153802\n",
            "Train Epoch: 7 | Batch Status: 12160/60000 (20%) | Loss: 0.164618\n",
            "Train Epoch: 7 | Batch Status: 12800/60000 (21%) | Loss: 0.035329\n",
            "Train Epoch: 7 | Batch Status: 13440/60000 (22%) | Loss: 0.133460\n",
            "Train Epoch: 7 | Batch Status: 14080/60000 (23%) | Loss: 0.203300\n",
            "Train Epoch: 7 | Batch Status: 14720/60000 (25%) | Loss: 0.057465\n",
            "Train Epoch: 7 | Batch Status: 15360/60000 (26%) | Loss: 0.076189\n",
            "Train Epoch: 7 | Batch Status: 16000/60000 (27%) | Loss: 0.088050\n",
            "Train Epoch: 7 | Batch Status: 16640/60000 (28%) | Loss: 0.212207\n",
            "Train Epoch: 7 | Batch Status: 17280/60000 (29%) | Loss: 0.139891\n",
            "Train Epoch: 7 | Batch Status: 17920/60000 (30%) | Loss: 0.058503\n",
            "Train Epoch: 7 | Batch Status: 18560/60000 (31%) | Loss: 0.036630\n",
            "Train Epoch: 7 | Batch Status: 19200/60000 (32%) | Loss: 0.142334\n",
            "Train Epoch: 7 | Batch Status: 19840/60000 (33%) | Loss: 0.106946\n",
            "Train Epoch: 7 | Batch Status: 20480/60000 (34%) | Loss: 0.036259\n",
            "Train Epoch: 7 | Batch Status: 21120/60000 (35%) | Loss: 0.142886\n",
            "Train Epoch: 7 | Batch Status: 21760/60000 (36%) | Loss: 0.066639\n",
            "Train Epoch: 7 | Batch Status: 22400/60000 (37%) | Loss: 0.029460\n",
            "Train Epoch: 7 | Batch Status: 23040/60000 (38%) | Loss: 0.124100\n",
            "Train Epoch: 7 | Batch Status: 23680/60000 (39%) | Loss: 0.097959\n",
            "Train Epoch: 7 | Batch Status: 24320/60000 (41%) | Loss: 0.470995\n",
            "Train Epoch: 7 | Batch Status: 24960/60000 (42%) | Loss: 0.069993\n",
            "Train Epoch: 7 | Batch Status: 25600/60000 (43%) | Loss: 0.025770\n",
            "Train Epoch: 7 | Batch Status: 26240/60000 (44%) | Loss: 0.129065\n",
            "Train Epoch: 7 | Batch Status: 26880/60000 (45%) | Loss: 0.124863\n",
            "Train Epoch: 7 | Batch Status: 27520/60000 (46%) | Loss: 0.170413\n",
            "Train Epoch: 7 | Batch Status: 28160/60000 (47%) | Loss: 0.124760\n",
            "Train Epoch: 7 | Batch Status: 28800/60000 (48%) | Loss: 0.372776\n",
            "Train Epoch: 7 | Batch Status: 29440/60000 (49%) | Loss: 0.051467\n",
            "Train Epoch: 7 | Batch Status: 30080/60000 (50%) | Loss: 0.191401\n",
            "Train Epoch: 7 | Batch Status: 30720/60000 (51%) | Loss: 0.122981\n",
            "Train Epoch: 7 | Batch Status: 31360/60000 (52%) | Loss: 0.036534\n",
            "Train Epoch: 7 | Batch Status: 32000/60000 (53%) | Loss: 0.164986\n",
            "Train Epoch: 7 | Batch Status: 32640/60000 (54%) | Loss: 0.170406\n",
            "Train Epoch: 7 | Batch Status: 33280/60000 (55%) | Loss: 0.160271\n",
            "Train Epoch: 7 | Batch Status: 33920/60000 (57%) | Loss: 0.253212\n",
            "Train Epoch: 7 | Batch Status: 34560/60000 (58%) | Loss: 0.229212\n",
            "Train Epoch: 7 | Batch Status: 35200/60000 (59%) | Loss: 0.118653\n",
            "Train Epoch: 7 | Batch Status: 35840/60000 (60%) | Loss: 0.135736\n",
            "Train Epoch: 7 | Batch Status: 36480/60000 (61%) | Loss: 0.076263\n",
            "Train Epoch: 7 | Batch Status: 37120/60000 (62%) | Loss: 0.176383\n",
            "Train Epoch: 7 | Batch Status: 37760/60000 (63%) | Loss: 0.084970\n",
            "Train Epoch: 7 | Batch Status: 38400/60000 (64%) | Loss: 0.141879\n",
            "Train Epoch: 7 | Batch Status: 39040/60000 (65%) | Loss: 0.129979\n",
            "Train Epoch: 7 | Batch Status: 39680/60000 (66%) | Loss: 0.056860\n",
            "Train Epoch: 7 | Batch Status: 40320/60000 (67%) | Loss: 0.241087\n",
            "Train Epoch: 7 | Batch Status: 40960/60000 (68%) | Loss: 0.151076\n",
            "Train Epoch: 7 | Batch Status: 41600/60000 (69%) | Loss: 0.485605\n",
            "Train Epoch: 7 | Batch Status: 42240/60000 (70%) | Loss: 0.079996\n",
            "Train Epoch: 7 | Batch Status: 42880/60000 (71%) | Loss: 0.078197\n",
            "Train Epoch: 7 | Batch Status: 43520/60000 (72%) | Loss: 0.119905\n",
            "Train Epoch: 7 | Batch Status: 44160/60000 (74%) | Loss: 0.104676\n",
            "Train Epoch: 7 | Batch Status: 44800/60000 (75%) | Loss: 0.040800\n",
            "Train Epoch: 7 | Batch Status: 45440/60000 (76%) | Loss: 0.182720\n",
            "Train Epoch: 7 | Batch Status: 46080/60000 (77%) | Loss: 0.059774\n",
            "Train Epoch: 7 | Batch Status: 46720/60000 (78%) | Loss: 0.098303\n",
            "Train Epoch: 7 | Batch Status: 47360/60000 (79%) | Loss: 0.069249\n",
            "Train Epoch: 7 | Batch Status: 48000/60000 (80%) | Loss: 0.059157\n",
            "Train Epoch: 7 | Batch Status: 48640/60000 (81%) | Loss: 0.097297\n",
            "Train Epoch: 7 | Batch Status: 49280/60000 (82%) | Loss: 0.116166\n",
            "Train Epoch: 7 | Batch Status: 49920/60000 (83%) | Loss: 0.097780\n",
            "Train Epoch: 7 | Batch Status: 50560/60000 (84%) | Loss: 0.090035\n",
            "Train Epoch: 7 | Batch Status: 51200/60000 (85%) | Loss: 0.044360\n",
            "Train Epoch: 7 | Batch Status: 51840/60000 (86%) | Loss: 0.129986\n",
            "Train Epoch: 7 | Batch Status: 52480/60000 (87%) | Loss: 0.036496\n",
            "Train Epoch: 7 | Batch Status: 53120/60000 (88%) | Loss: 0.111963\n",
            "Train Epoch: 7 | Batch Status: 53760/60000 (90%) | Loss: 0.077658\n",
            "Train Epoch: 7 | Batch Status: 54400/60000 (91%) | Loss: 0.072571\n",
            "Train Epoch: 7 | Batch Status: 55040/60000 (92%) | Loss: 0.256693\n",
            "Train Epoch: 7 | Batch Status: 55680/60000 (93%) | Loss: 0.193369\n",
            "Train Epoch: 7 | Batch Status: 56320/60000 (94%) | Loss: 0.075272\n",
            "Train Epoch: 7 | Batch Status: 56960/60000 (95%) | Loss: 0.057378\n",
            "Train Epoch: 7 | Batch Status: 57600/60000 (96%) | Loss: 0.074106\n",
            "Train Epoch: 7 | Batch Status: 58240/60000 (97%) | Loss: 0.064893\n",
            "Train Epoch: 7 | Batch Status: 58880/60000 (98%) | Loss: 0.163483\n",
            "Train Epoch: 7 | Batch Status: 59520/60000 (99%) | Loss: 0.039951\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0022, Accuracy: 9609/10000 (96%)\n",
            "Testing time: 0m 14s\n",
            "Train Epoch: 8 | Batch Status: 0/60000 (0%) | Loss: 0.049899\n",
            "Train Epoch: 8 | Batch Status: 640/60000 (1%) | Loss: 0.140903\n",
            "Train Epoch: 8 | Batch Status: 1280/60000 (2%) | Loss: 0.220897\n",
            "Train Epoch: 8 | Batch Status: 1920/60000 (3%) | Loss: 0.037966\n",
            "Train Epoch: 8 | Batch Status: 2560/60000 (4%) | Loss: 0.179268\n",
            "Train Epoch: 8 | Batch Status: 3200/60000 (5%) | Loss: 0.037226\n",
            "Train Epoch: 8 | Batch Status: 3840/60000 (6%) | Loss: 0.126490\n",
            "Train Epoch: 8 | Batch Status: 4480/60000 (7%) | Loss: 0.135708\n",
            "Train Epoch: 8 | Batch Status: 5120/60000 (9%) | Loss: 0.067613\n",
            "Train Epoch: 8 | Batch Status: 5760/60000 (10%) | Loss: 0.246590\n",
            "Train Epoch: 8 | Batch Status: 6400/60000 (11%) | Loss: 0.226115\n",
            "Train Epoch: 8 | Batch Status: 7040/60000 (12%) | Loss: 0.113626\n",
            "Train Epoch: 8 | Batch Status: 7680/60000 (13%) | Loss: 0.078755\n",
            "Train Epoch: 8 | Batch Status: 8320/60000 (14%) | Loss: 0.097839\n",
            "Train Epoch: 8 | Batch Status: 8960/60000 (15%) | Loss: 0.153723\n",
            "Train Epoch: 8 | Batch Status: 9600/60000 (16%) | Loss: 0.113671\n",
            "Train Epoch: 8 | Batch Status: 10240/60000 (17%) | Loss: 0.115715\n",
            "Train Epoch: 8 | Batch Status: 10880/60000 (18%) | Loss: 0.153182\n",
            "Train Epoch: 8 | Batch Status: 11520/60000 (19%) | Loss: 0.257995\n",
            "Train Epoch: 8 | Batch Status: 12160/60000 (20%) | Loss: 0.105070\n",
            "Train Epoch: 8 | Batch Status: 12800/60000 (21%) | Loss: 0.077005\n",
            "Train Epoch: 8 | Batch Status: 13440/60000 (22%) | Loss: 0.164622\n",
            "Train Epoch: 8 | Batch Status: 14080/60000 (23%) | Loss: 0.195266\n",
            "Train Epoch: 8 | Batch Status: 14720/60000 (25%) | Loss: 0.112378\n",
            "Train Epoch: 8 | Batch Status: 15360/60000 (26%) | Loss: 0.303754\n",
            "Train Epoch: 8 | Batch Status: 16000/60000 (27%) | Loss: 0.130964\n",
            "Train Epoch: 8 | Batch Status: 16640/60000 (28%) | Loss: 0.032645\n",
            "Train Epoch: 8 | Batch Status: 17280/60000 (29%) | Loss: 0.100476\n",
            "Train Epoch: 8 | Batch Status: 17920/60000 (30%) | Loss: 0.029298\n",
            "Train Epoch: 8 | Batch Status: 18560/60000 (31%) | Loss: 0.187906\n",
            "Train Epoch: 8 | Batch Status: 19200/60000 (32%) | Loss: 0.084153\n",
            "Train Epoch: 8 | Batch Status: 19840/60000 (33%) | Loss: 0.140020\n",
            "Train Epoch: 8 | Batch Status: 20480/60000 (34%) | Loss: 0.038347\n",
            "Train Epoch: 8 | Batch Status: 21120/60000 (35%) | Loss: 0.059036\n",
            "Train Epoch: 8 | Batch Status: 21760/60000 (36%) | Loss: 0.084555\n",
            "Train Epoch: 8 | Batch Status: 22400/60000 (37%) | Loss: 0.049451\n",
            "Train Epoch: 8 | Batch Status: 23040/60000 (38%) | Loss: 0.025884\n",
            "Train Epoch: 8 | Batch Status: 23680/60000 (39%) | Loss: 0.086003\n",
            "Train Epoch: 8 | Batch Status: 24320/60000 (41%) | Loss: 0.173310\n",
            "Train Epoch: 8 | Batch Status: 24960/60000 (42%) | Loss: 0.169498\n",
            "Train Epoch: 8 | Batch Status: 25600/60000 (43%) | Loss: 0.192526\n",
            "Train Epoch: 8 | Batch Status: 26240/60000 (44%) | Loss: 0.068823\n",
            "Train Epoch: 8 | Batch Status: 26880/60000 (45%) | Loss: 0.015288\n",
            "Train Epoch: 8 | Batch Status: 27520/60000 (46%) | Loss: 0.287321\n",
            "Train Epoch: 8 | Batch Status: 28160/60000 (47%) | Loss: 0.102697\n",
            "Train Epoch: 8 | Batch Status: 28800/60000 (48%) | Loss: 0.078629\n",
            "Train Epoch: 8 | Batch Status: 29440/60000 (49%) | Loss: 0.145616\n",
            "Train Epoch: 8 | Batch Status: 30080/60000 (50%) | Loss: 0.166976\n",
            "Train Epoch: 8 | Batch Status: 30720/60000 (51%) | Loss: 0.076501\n",
            "Train Epoch: 8 | Batch Status: 31360/60000 (52%) | Loss: 0.028736\n",
            "Train Epoch: 8 | Batch Status: 32000/60000 (53%) | Loss: 0.056088\n",
            "Train Epoch: 8 | Batch Status: 32640/60000 (54%) | Loss: 0.084359\n",
            "Train Epoch: 8 | Batch Status: 33280/60000 (55%) | Loss: 0.028231\n",
            "Train Epoch: 8 | Batch Status: 33920/60000 (57%) | Loss: 0.060186\n",
            "Train Epoch: 8 | Batch Status: 34560/60000 (58%) | Loss: 0.063826\n",
            "Train Epoch: 8 | Batch Status: 35200/60000 (59%) | Loss: 0.328357\n",
            "Train Epoch: 8 | Batch Status: 35840/60000 (60%) | Loss: 0.144776\n",
            "Train Epoch: 8 | Batch Status: 36480/60000 (61%) | Loss: 0.142546\n",
            "Train Epoch: 8 | Batch Status: 37120/60000 (62%) | Loss: 0.050684\n",
            "Train Epoch: 8 | Batch Status: 37760/60000 (63%) | Loss: 0.113313\n",
            "Train Epoch: 8 | Batch Status: 38400/60000 (64%) | Loss: 0.142871\n",
            "Train Epoch: 8 | Batch Status: 39040/60000 (65%) | Loss: 0.153564\n",
            "Train Epoch: 8 | Batch Status: 39680/60000 (66%) | Loss: 0.042279\n",
            "Train Epoch: 8 | Batch Status: 40320/60000 (67%) | Loss: 0.130991\n",
            "Train Epoch: 8 | Batch Status: 40960/60000 (68%) | Loss: 0.241520\n",
            "Train Epoch: 8 | Batch Status: 41600/60000 (69%) | Loss: 0.206822\n",
            "Train Epoch: 8 | Batch Status: 42240/60000 (70%) | Loss: 0.205938\n",
            "Train Epoch: 8 | Batch Status: 42880/60000 (71%) | Loss: 0.053266\n",
            "Train Epoch: 8 | Batch Status: 43520/60000 (72%) | Loss: 0.161847\n",
            "Train Epoch: 8 | Batch Status: 44160/60000 (74%) | Loss: 0.052254\n",
            "Train Epoch: 8 | Batch Status: 44800/60000 (75%) | Loss: 0.099246\n",
            "Train Epoch: 8 | Batch Status: 45440/60000 (76%) | Loss: 0.157682\n",
            "Train Epoch: 8 | Batch Status: 46080/60000 (77%) | Loss: 0.201706\n",
            "Train Epoch: 8 | Batch Status: 46720/60000 (78%) | Loss: 0.085240\n",
            "Train Epoch: 8 | Batch Status: 47360/60000 (79%) | Loss: 0.073709\n",
            "Train Epoch: 8 | Batch Status: 48000/60000 (80%) | Loss: 0.059713\n",
            "Train Epoch: 8 | Batch Status: 48640/60000 (81%) | Loss: 0.088667\n",
            "Train Epoch: 8 | Batch Status: 49280/60000 (82%) | Loss: 0.025915\n",
            "Train Epoch: 8 | Batch Status: 49920/60000 (83%) | Loss: 0.270421\n",
            "Train Epoch: 8 | Batch Status: 50560/60000 (84%) | Loss: 0.091633\n",
            "Train Epoch: 8 | Batch Status: 51200/60000 (85%) | Loss: 0.196700\n",
            "Train Epoch: 8 | Batch Status: 51840/60000 (86%) | Loss: 0.124691\n",
            "Train Epoch: 8 | Batch Status: 52480/60000 (87%) | Loss: 0.082347\n",
            "Train Epoch: 8 | Batch Status: 53120/60000 (88%) | Loss: 0.043466\n",
            "Train Epoch: 8 | Batch Status: 53760/60000 (90%) | Loss: 0.116844\n",
            "Train Epoch: 8 | Batch Status: 54400/60000 (91%) | Loss: 0.041614\n",
            "Train Epoch: 8 | Batch Status: 55040/60000 (92%) | Loss: 0.060625\n",
            "Train Epoch: 8 | Batch Status: 55680/60000 (93%) | Loss: 0.061791\n",
            "Train Epoch: 8 | Batch Status: 56320/60000 (94%) | Loss: 0.088795\n",
            "Train Epoch: 8 | Batch Status: 56960/60000 (95%) | Loss: 0.127383\n",
            "Train Epoch: 8 | Batch Status: 57600/60000 (96%) | Loss: 0.176451\n",
            "Train Epoch: 8 | Batch Status: 58240/60000 (97%) | Loss: 0.093432\n",
            "Train Epoch: 8 | Batch Status: 58880/60000 (98%) | Loss: 0.142532\n",
            "Train Epoch: 8 | Batch Status: 59520/60000 (99%) | Loss: 0.026457\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0018, Accuracy: 9675/10000 (97%)\n",
            "Testing time: 0m 14s\n",
            "Train Epoch: 9 | Batch Status: 0/60000 (0%) | Loss: 0.107126\n",
            "Train Epoch: 9 | Batch Status: 640/60000 (1%) | Loss: 0.039074\n",
            "Train Epoch: 9 | Batch Status: 1280/60000 (2%) | Loss: 0.116742\n",
            "Train Epoch: 9 | Batch Status: 1920/60000 (3%) | Loss: 0.153176\n",
            "Train Epoch: 9 | Batch Status: 2560/60000 (4%) | Loss: 0.033463\n",
            "Train Epoch: 9 | Batch Status: 3200/60000 (5%) | Loss: 0.198497\n",
            "Train Epoch: 9 | Batch Status: 3840/60000 (6%) | Loss: 0.089748\n",
            "Train Epoch: 9 | Batch Status: 4480/60000 (7%) | Loss: 0.089910\n",
            "Train Epoch: 9 | Batch Status: 5120/60000 (9%) | Loss: 0.109891\n",
            "Train Epoch: 9 | Batch Status: 5760/60000 (10%) | Loss: 0.172015\n",
            "Train Epoch: 9 | Batch Status: 6400/60000 (11%) | Loss: 0.049312\n",
            "Train Epoch: 9 | Batch Status: 7040/60000 (12%) | Loss: 0.014348\n",
            "Train Epoch: 9 | Batch Status: 7680/60000 (13%) | Loss: 0.158978\n",
            "Train Epoch: 9 | Batch Status: 8320/60000 (14%) | Loss: 0.079337\n",
            "Train Epoch: 9 | Batch Status: 8960/60000 (15%) | Loss: 0.069975\n",
            "Train Epoch: 9 | Batch Status: 9600/60000 (16%) | Loss: 0.104931\n",
            "Train Epoch: 9 | Batch Status: 10240/60000 (17%) | Loss: 0.093255\n",
            "Train Epoch: 9 | Batch Status: 10880/60000 (18%) | Loss: 0.040252\n",
            "Train Epoch: 9 | Batch Status: 11520/60000 (19%) | Loss: 0.087387\n",
            "Train Epoch: 9 | Batch Status: 12160/60000 (20%) | Loss: 0.172198\n",
            "Train Epoch: 9 | Batch Status: 12800/60000 (21%) | Loss: 0.083008\n",
            "Train Epoch: 9 | Batch Status: 13440/60000 (22%) | Loss: 0.025763\n",
            "Train Epoch: 9 | Batch Status: 14080/60000 (23%) | Loss: 0.060125\n",
            "Train Epoch: 9 | Batch Status: 14720/60000 (25%) | Loss: 0.088576\n",
            "Train Epoch: 9 | Batch Status: 15360/60000 (26%) | Loss: 0.115528\n",
            "Train Epoch: 9 | Batch Status: 16000/60000 (27%) | Loss: 0.122947\n",
            "Train Epoch: 9 | Batch Status: 16640/60000 (28%) | Loss: 0.137463\n",
            "Train Epoch: 9 | Batch Status: 17280/60000 (29%) | Loss: 0.169578\n",
            "Train Epoch: 9 | Batch Status: 17920/60000 (30%) | Loss: 0.109359\n",
            "Train Epoch: 9 | Batch Status: 18560/60000 (31%) | Loss: 0.133777\n",
            "Train Epoch: 9 | Batch Status: 19200/60000 (32%) | Loss: 0.182883\n",
            "Train Epoch: 9 | Batch Status: 19840/60000 (33%) | Loss: 0.079830\n",
            "Train Epoch: 9 | Batch Status: 20480/60000 (34%) | Loss: 0.092513\n",
            "Train Epoch: 9 | Batch Status: 21120/60000 (35%) | Loss: 0.139463\n",
            "Train Epoch: 9 | Batch Status: 21760/60000 (36%) | Loss: 0.169690\n",
            "Train Epoch: 9 | Batch Status: 22400/60000 (37%) | Loss: 0.091926\n",
            "Train Epoch: 9 | Batch Status: 23040/60000 (38%) | Loss: 0.054537\n",
            "Train Epoch: 9 | Batch Status: 23680/60000 (39%) | Loss: 0.154190\n",
            "Train Epoch: 9 | Batch Status: 24320/60000 (41%) | Loss: 0.153062\n",
            "Train Epoch: 9 | Batch Status: 24960/60000 (42%) | Loss: 0.050888\n",
            "Train Epoch: 9 | Batch Status: 25600/60000 (43%) | Loss: 0.157463\n",
            "Train Epoch: 9 | Batch Status: 26240/60000 (44%) | Loss: 0.095039\n",
            "Train Epoch: 9 | Batch Status: 26880/60000 (45%) | Loss: 0.167663\n",
            "Train Epoch: 9 | Batch Status: 27520/60000 (46%) | Loss: 0.052940\n",
            "Train Epoch: 9 | Batch Status: 28160/60000 (47%) | Loss: 0.095422\n",
            "Train Epoch: 9 | Batch Status: 28800/60000 (48%) | Loss: 0.060016\n",
            "Train Epoch: 9 | Batch Status: 29440/60000 (49%) | Loss: 0.113480\n",
            "Train Epoch: 9 | Batch Status: 30080/60000 (50%) | Loss: 0.089279\n",
            "Train Epoch: 9 | Batch Status: 30720/60000 (51%) | Loss: 0.139958\n",
            "Train Epoch: 9 | Batch Status: 31360/60000 (52%) | Loss: 0.046756\n",
            "Train Epoch: 9 | Batch Status: 32000/60000 (53%) | Loss: 0.048926\n",
            "Train Epoch: 9 | Batch Status: 32640/60000 (54%) | Loss: 0.018238\n",
            "Train Epoch: 9 | Batch Status: 33280/60000 (55%) | Loss: 0.033853\n",
            "Train Epoch: 9 | Batch Status: 33920/60000 (57%) | Loss: 0.055030\n",
            "Train Epoch: 9 | Batch Status: 34560/60000 (58%) | Loss: 0.035479\n",
            "Train Epoch: 9 | Batch Status: 35200/60000 (59%) | Loss: 0.094360\n",
            "Train Epoch: 9 | Batch Status: 35840/60000 (60%) | Loss: 0.140934\n",
            "Train Epoch: 9 | Batch Status: 36480/60000 (61%) | Loss: 0.037963\n",
            "Train Epoch: 9 | Batch Status: 37120/60000 (62%) | Loss: 0.165963\n",
            "Train Epoch: 9 | Batch Status: 37760/60000 (63%) | Loss: 0.151147\n",
            "Train Epoch: 9 | Batch Status: 38400/60000 (64%) | Loss: 0.098563\n",
            "Train Epoch: 9 | Batch Status: 39040/60000 (65%) | Loss: 0.057000\n",
            "Train Epoch: 9 | Batch Status: 39680/60000 (66%) | Loss: 0.048405\n",
            "Train Epoch: 9 | Batch Status: 40320/60000 (67%) | Loss: 0.057102\n",
            "Train Epoch: 9 | Batch Status: 40960/60000 (68%) | Loss: 0.025540\n",
            "Train Epoch: 9 | Batch Status: 41600/60000 (69%) | Loss: 0.119189\n",
            "Train Epoch: 9 | Batch Status: 42240/60000 (70%) | Loss: 0.057052\n",
            "Train Epoch: 9 | Batch Status: 42880/60000 (71%) | Loss: 0.114687\n",
            "Train Epoch: 9 | Batch Status: 43520/60000 (72%) | Loss: 0.060651\n",
            "Train Epoch: 9 | Batch Status: 44160/60000 (74%) | Loss: 0.055209\n",
            "Train Epoch: 9 | Batch Status: 44800/60000 (75%) | Loss: 0.078025\n",
            "Train Epoch: 9 | Batch Status: 45440/60000 (76%) | Loss: 0.087887\n",
            "Train Epoch: 9 | Batch Status: 46080/60000 (77%) | Loss: 0.060533\n",
            "Train Epoch: 9 | Batch Status: 46720/60000 (78%) | Loss: 0.093320\n",
            "Train Epoch: 9 | Batch Status: 47360/60000 (79%) | Loss: 0.042395\n",
            "Train Epoch: 9 | Batch Status: 48000/60000 (80%) | Loss: 0.043297\n",
            "Train Epoch: 9 | Batch Status: 48640/60000 (81%) | Loss: 0.033177\n",
            "Train Epoch: 9 | Batch Status: 49280/60000 (82%) | Loss: 0.046457\n",
            "Train Epoch: 9 | Batch Status: 49920/60000 (83%) | Loss: 0.128364\n",
            "Train Epoch: 9 | Batch Status: 50560/60000 (84%) | Loss: 0.034725\n",
            "Train Epoch: 9 | Batch Status: 51200/60000 (85%) | Loss: 0.132155\n",
            "Train Epoch: 9 | Batch Status: 51840/60000 (86%) | Loss: 0.161884\n",
            "Train Epoch: 9 | Batch Status: 52480/60000 (87%) | Loss: 0.084864\n",
            "Train Epoch: 9 | Batch Status: 53120/60000 (88%) | Loss: 0.151269\n",
            "Train Epoch: 9 | Batch Status: 53760/60000 (90%) | Loss: 0.186948\n",
            "Train Epoch: 9 | Batch Status: 54400/60000 (91%) | Loss: 0.024508\n",
            "Train Epoch: 9 | Batch Status: 55040/60000 (92%) | Loss: 0.086380\n",
            "Train Epoch: 9 | Batch Status: 55680/60000 (93%) | Loss: 0.119805\n",
            "Train Epoch: 9 | Batch Status: 56320/60000 (94%) | Loss: 0.098633\n",
            "Train Epoch: 9 | Batch Status: 56960/60000 (95%) | Loss: 0.093299\n",
            "Train Epoch: 9 | Batch Status: 57600/60000 (96%) | Loss: 0.152517\n",
            "Train Epoch: 9 | Batch Status: 58240/60000 (97%) | Loss: 0.107313\n",
            "Train Epoch: 9 | Batch Status: 58880/60000 (98%) | Loss: 0.133179\n",
            "Train Epoch: 9 | Batch Status: 59520/60000 (99%) | Loss: 0.174155\n",
            "Training time: 0m 13s\n",
            "===========================\n",
            "Test set: Average loss: 0.0017, Accuracy: 9666/10000 (97%)\n",
            "Testing time: 0m 14s\n",
            "Total Time: 2m 6s\n",
            "Model was trained on cpu!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2GLiVsoZA_O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}